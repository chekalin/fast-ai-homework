{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/chekalin/Dev/fast-ai-homework/seedling-classification'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOME = '/home/chekalin/Dev/fast-ai-homework/seedling-classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_HOME = HOME + '/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%rm -rf test/ train/ valid/ results/ sample/ sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip test.zip && unzip train.zip && unzip sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = os.listdir(DATA_HOME + '/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for category in categories: \n",
    "    %mkdir -p \"$DATA_HOME/valid/$category\"\n",
    "    %mkdir -p \"$DATA_HOME/sample/valid/$category\"\n",
    "    %mkdir -p \"$DATA_HOME/sample/train/$category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir -p \"$DATA_HOME/results\"\n",
    "%mkdir -p \"$DATA_HOME/sample/results\"\n",
    "%mkdir -p \"$DATA_HOME/test/unknown\"\n",
    "%mkdir -p \"$DATA_HOME/sample/test/unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% cd $DATA_HOME/test\n",
    "!echo *.png | xargs mv -t unknown/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% cd $DATA_HOME\n",
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_HOME/train\n",
    "training_files = glob('*/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_set_size = int(len(training_files) * .1)\n",
    "\n",
    "shuffled_training_files = np.random.permutation(training_files).tolist()\n",
    "for i in range(validation_set_size): \n",
    "    random_file = shuffled_training_files.pop()\n",
    "    os.rename(random_file, DATA_HOME + '/valid/' + random_file)\n",
    "\n",
    "sample_training_set_size = 1000\n",
    "for i in range(sample_training_set_size): \n",
    "    random_file = shuffled_training_files.pop()\n",
    "    copyfile(random_file, DATA_HOME + '/sample/train/' + random_file)\n",
    "\n",
    "sample_validation_set_size = 1000\n",
    "for i in range(sample_validation_set_size): \n",
    "    random_file = shuffled_training_files.pop()\n",
    "    copyfile(random_file, DATA_HOME + '/sample/valid/' + random_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_HOME/test\n",
    "test_files = glob('*/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_test_set_size = 100\n",
    "for filename in test_files[:sample_test_set_size]: copyfile(filename, DATA_HOME + '/sample/test/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_HOME\n",
    "for dirpath, dirnames, filenames in os.walk(DATA_HOME):\n",
    "    relative = dirpath[len(os.getcwd()):]\n",
    "    if (len(filenames) and len(relative)): print \"Files in {}: {}\".format(relative, len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "def addConvBlock(model, layers, filters):\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "        model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(3,224,224)))\n",
    "addConvBlock(model, 2, 64)\n",
    "addConvBlock(model, 2, 128)\n",
    "addConvBlock(model, 3, 256)\n",
    "addConvBlock(model, 3, 512)\n",
    "addConvBlock(model, 3, 512)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_33 (BatchNorm (None, 3, 224, 224)   12          batchnormalization_input_3[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_27 (ZeroPadding2D) (None, 3, 226, 226)   0           batchnormalization_33[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_27 (Convolution2D) (None, 64, 224, 224)  1792        zeropadding2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_34 (BatchNorm (None, 64, 224, 224)  256         convolution2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_28 (ZeroPadding2D) (None, 64, 226, 226)  0           batchnormalization_34[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_28 (Convolution2D) (None, 64, 224, 224)  36928       zeropadding2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_35 (BatchNorm (None, 64, 224, 224)  256         convolution2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_11 (MaxPooling2D)   (None, 64, 112, 112)  0           batchnormalization_35[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_29 (ZeroPadding2D) (None, 64, 114, 114)  0           maxpooling2d_11[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_29 (Convolution2D) (None, 128, 112, 112) 73856       zeropadding2d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_36 (BatchNorm (None, 128, 112, 112) 512         convolution2d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_30 (ZeroPadding2D) (None, 128, 114, 114) 0           batchnormalization_36[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_30 (Convolution2D) (None, 128, 112, 112) 147584      zeropadding2d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_37 (BatchNorm (None, 128, 112, 112) 512         convolution2d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_12 (MaxPooling2D)   (None, 128, 56, 56)   0           batchnormalization_37[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_31 (ZeroPadding2D) (None, 128, 58, 58)   0           maxpooling2d_12[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_31 (Convolution2D) (None, 256, 56, 56)   295168      zeropadding2d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_38 (BatchNorm (None, 256, 56, 56)   1024        convolution2d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_32 (ZeroPadding2D) (None, 256, 58, 58)   0           batchnormalization_38[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_32 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_39 (BatchNorm (None, 256, 56, 56)   1024        convolution2d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_33 (ZeroPadding2D) (None, 256, 58, 58)   0           batchnormalization_39[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_33 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_40 (BatchNorm (None, 256, 56, 56)   1024        convolution2d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_13 (MaxPooling2D)   (None, 256, 28, 28)   0           batchnormalization_40[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_34 (ZeroPadding2D) (None, 256, 30, 30)   0           maxpooling2d_13[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_34 (Convolution2D) (None, 512, 28, 28)   1180160     zeropadding2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_41 (BatchNorm (None, 512, 28, 28)   2048        convolution2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_35 (ZeroPadding2D) (None, 512, 30, 30)   0           batchnormalization_41[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_35 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_42 (BatchNorm (None, 512, 28, 28)   2048        convolution2d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_36 (ZeroPadding2D) (None, 512, 30, 30)   0           batchnormalization_42[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_36 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_43 (BatchNorm (None, 512, 28, 28)   2048        convolution2d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_14 (MaxPooling2D)   (None, 512, 14, 14)   0           batchnormalization_43[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_37 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_14[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_37 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_37[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_44 (BatchNorm (None, 512, 14, 14)   2048        convolution2d_37[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_38 (ZeroPadding2D) (None, 512, 16, 16)   0           batchnormalization_44[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_38 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_38[0][0]           \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchnormalization_45 (BatchNorm (None, 512, 14, 14)   2048        convolution2d_38[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_39 (ZeroPadding2D) (None, 512, 16, 16)   0           batchnormalization_45[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_39 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_46 (BatchNorm (None, 512, 14, 14)   2048        convolution2d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_15 (MaxPooling2D)   (None, 512, 7, 7)     0           batchnormalization_46[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 25088)         0           maxpooling2d_15[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 4096)          102764544   flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_47 (BatchNorm (None, 4096)          16384       dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 4096)          0           batchnormalization_47[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 4096)          16781312    dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_48 (BatchNorm (None, 4096)          16384       dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 4096)          0           batchnormalization_48[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 12)            49164       dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,359,384\n",
      "Trainable params: 134,334,546\n",
      "Non-trainable params: 24,838\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = DATA_HOME + '/sample'\n",
    "path = DATA_HOME\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def get_batches(path, gen=image.ImageDataGenerator(), shuffle=True, batch_size=8, class_mode='categorical'):\n",
    "        return gen.flow_from_directory(path, \n",
    "                                       target_size=(224,224),\n",
    "                                       class_mode=class_mode, \n",
    "                                       shuffle=shuffle, \n",
    "                                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, \n",
    "                               height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4275 images belonging to 12 classes.\n",
      "Found 475 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path + '/train', batch_size=batch_size, gen=gen)\n",
    "val_batches = get_batches(path + '/valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4275/4275 [==============================] - 278s - loss: 3.6649 - acc: 0.2847 - val_loss: 11.8105 - val_acc: 0.1453\n",
      "Epoch 2/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.8511 - acc: 0.4012 - val_loss: 5.5046 - val_acc: 0.2295\n",
      "Epoch 3/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.5083 - acc: 0.4601 - val_loss: 2.5994 - val_acc: 0.5432\n",
      "Epoch 4/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.2371 - acc: 0.5008 - val_loss: 2.0632 - val_acc: 0.5874\n",
      "Epoch 5/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.0938 - acc: 0.5160 - val_loss: 5.0370 - val_acc: 0.2442\n",
      "Epoch 6/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.1103 - acc: 0.5120 - val_loss: 6.1353 - val_acc: 0.3032\n",
      "Epoch 7/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.0528 - acc: 0.5462 - val_loss: 2.5986 - val_acc: 0.5011\n",
      "Epoch 8/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.6508 - acc: 0.5855 - val_loss: 1.7174 - val_acc: 0.6147\n",
      "Epoch 9/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.5374 - acc: 0.6145 - val_loss: 4.1810 - val_acc: 0.3768\n",
      "Epoch 10/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.7807 - acc: 0.5747 - val_loss: 2.9443 - val_acc: 0.6105\n",
      "Epoch 11/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.4267 - acc: 0.6325 - val_loss: 1.3602 - val_acc: 0.6884\n",
      "Epoch 12/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.3904 - acc: 0.6430 - val_loss: 4.4502 - val_acc: 0.3789\n",
      "Epoch 13/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.8894 - acc: 0.5874 - val_loss: 10.2255 - val_acc: 0.1958\n",
      "Epoch 14/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.3937 - acc: 0.5471 - val_loss: 3.0319 - val_acc: 0.5284\n",
      "Epoch 15/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.0668 - acc: 0.5287 - val_loss: 3.3031 - val_acc: 0.3642\n",
      "Epoch 16/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.6387 - acc: 0.6030 - val_loss: 1.6253 - val_acc: 0.6484\n",
      "Epoch 17/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.0039 - acc: 0.5366 - val_loss: 8.4286 - val_acc: 0.1705\n",
      "Epoch 18/50\n",
      "4275/4275 [==============================] - 278s - loss: 3.0876 - acc: 0.2985 - val_loss: 1.5908 - val_acc: 0.4968\n",
      "Epoch 19/50\n",
      "4275/4275 [==============================] - 277s - loss: 2.1615 - acc: 0.4440 - val_loss: 5.4137 - val_acc: 0.3389\n",
      "Epoch 20/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.2755 - acc: 0.4117 - val_loss: 1.7231 - val_acc: 0.4589\n",
      "Epoch 21/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.6782 - acc: 0.3752 - val_loss: 3.3968 - val_acc: 0.3979\n",
      "Epoch 22/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.4109 - acc: 0.3773 - val_loss: 2.4132 - val_acc: 0.3579\n",
      "Epoch 23/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.8693 - acc: 0.3015 - val_loss: 1.9914 - val_acc: 0.4568\n",
      "Epoch 24/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.3603 - acc: 0.3694 - val_loss: 2.7442 - val_acc: 0.3874\n",
      "Epoch 25/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.2232 - acc: 0.4281 - val_loss: 1.5418 - val_acc: 0.5600\n",
      "Epoch 26/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.0448 - acc: 0.4634 - val_loss: 1.4267 - val_acc: 0.5853\n",
      "Epoch 27/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.8365 - acc: 0.5008 - val_loss: 1.4790 - val_acc: 0.5916\n",
      "Epoch 28/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.0965 - acc: 0.4419 - val_loss: 1.4309 - val_acc: 0.5074\n",
      "Epoch 29/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.8017 - acc: 0.5062 - val_loss: 3.2051 - val_acc: 0.4968\n",
      "Epoch 30/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.8296 - acc: 0.5167 - val_loss: 1.8921 - val_acc: 0.5284\n",
      "Epoch 31/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.9288 - acc: 0.5137 - val_loss: 9.4880 - val_acc: 0.2505\n",
      "Epoch 32/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.4677 - acc: 0.4316 - val_loss: 1.8194 - val_acc: 0.4800\n",
      "Epoch 33/50\n",
      "4275/4275 [==============================] - 278s - loss: 3.0381 - acc: 0.3284 - val_loss: 3.1639 - val_acc: 0.4695\n",
      "Epoch 34/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.4263 - acc: 0.3949 - val_loss: 2.0086 - val_acc: 0.4800\n",
      "Epoch 35/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.0097 - acc: 0.4727 - val_loss: 1.4012 - val_acc: 0.6211\n",
      "Epoch 36/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.9345 - acc: 0.4896 - val_loss: 1.1178 - val_acc: 0.6337\n",
      "Epoch 37/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.8401 - acc: 0.5298 - val_loss: 2.0425 - val_acc: 0.5979\n",
      "Epoch 38/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.9947 - acc: 0.4968 - val_loss: 1.4236 - val_acc: 0.6063\n",
      "Epoch 39/50\n",
      "4275/4275 [==============================] - 278s - loss: 3.2438 - acc: 0.2482 - val_loss: 6.6216 - val_acc: 0.1347\n",
      "Epoch 40/50\n",
      "4275/4275 [==============================] - 278s - loss: 3.4812 - acc: 0.2002 - val_loss: 3.3145 - val_acc: 0.2821\n",
      "Epoch 41/50\n",
      "4275/4275 [==============================] - 278s - loss: 3.3125 - acc: 0.2332 - val_loss: 5.6288 - val_acc: 0.1853\n",
      "Epoch 42/50\n",
      "4275/4275 [==============================] - 278s - loss: 3.1405 - acc: 0.2262 - val_loss: 3.4255 - val_acc: 0.2716\n",
      "Epoch 43/50\n",
      "4275/4275 [==============================] - 279s - loss: 3.0012 - acc: 0.2519 - val_loss: 2.7617 - val_acc: 0.2611\n",
      "Epoch 44/50\n",
      "4275/4275 [==============================] - 278s - loss: 3.1130 - acc: 0.1930 - val_loss: 3.1375 - val_acc: 0.1221\n",
      "Epoch 45/50\n",
      "4275/4275 [==============================] - 279s - loss: 3.2801 - acc: 0.1729 - val_loss: 7.3088 - val_acc: 0.2105\n",
      "Epoch 46/50\n",
      "4275/4275 [==============================] - 278s - loss: 3.2014 - acc: 0.1787 - val_loss: 2.3739 - val_acc: 0.2526\n",
      "Epoch 47/50\n",
      "4275/4275 [==============================] - 278s - loss: 3.1062 - acc: 0.2211 - val_loss: 3.4886 - val_acc: 0.2905\n",
      "Epoch 48/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.9345 - acc: 0.2664 - val_loss: 2.2521 - val_acc: 0.3389\n",
      "Epoch 49/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.9221 - acc: 0.2543 - val_loss: 2.6356 - val_acc: 0.2611\n",
      "Epoch 50/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.7558 - acc: 0.2924 - val_loss: 2.3780 - val_acc: 0.4484\n",
      "fitting 50 epochs took 13956 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "fitting_start_time = time.time()\n",
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=50, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model.save_weights('weights-50-epochs.h5')\n",
    "print \"fitting 50 epochs took {} seconds\".format(int(time.time() - fitting_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.7872 - acc: 0.2882 - val_loss: 2.8148 - val_acc: 0.2484\n",
      "Epoch 2/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.6926 - acc: 0.3027 - val_loss: 1.9908 - val_acc: 0.3979\n",
      "Epoch 3/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.5057 - acc: 0.3448 - val_loss: 1.7440 - val_acc: 0.4021\n",
      "Epoch 4/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.4588 - acc: 0.3163 - val_loss: 3.3812 - val_acc: 0.3453\n",
      "Epoch 5/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.5225 - acc: 0.3102 - val_loss: 2.5618 - val_acc: 0.2821\n",
      "Epoch 6/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.3399 - acc: 0.2559 - val_loss: 1.8523 - val_acc: 0.3684\n",
      "Epoch 7/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.2657 - acc: 0.2758 - val_loss: 2.0235 - val_acc: 0.3811\n",
      "Epoch 8/50\n",
      "4275/4275 [==============================] - 280s - loss: 2.1721 - acc: 0.2933 - val_loss: 1.8387 - val_acc: 0.4147\n",
      "Epoch 9/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.1105 - acc: 0.3188 - val_loss: 1.9481 - val_acc: 0.3958\n",
      "Epoch 10/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.9559 - acc: 0.3392 - val_loss: 4.3600 - val_acc: 0.3284\n",
      "Epoch 11/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.1137 - acc: 0.3291 - val_loss: 4.4564 - val_acc: 0.2337\n",
      "Epoch 12/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.3416 - acc: 0.2561 - val_loss: 3.0784 - val_acc: 0.2232\n",
      "Epoch 13/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.0978 - acc: 0.2929 - val_loss: 1.6919 - val_acc: 0.4274\n",
      "Epoch 14/50\n",
      "4275/4275 [==============================] - 280s - loss: 1.9123 - acc: 0.3497 - val_loss: 1.8219 - val_acc: 0.4505\n",
      "Epoch 15/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.8433 - acc: 0.3626 - val_loss: 4.8440 - val_acc: 0.2863\n",
      "Epoch 16/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.8038 - acc: 0.3738 - val_loss: 4.7418 - val_acc: 0.3137\n",
      "Epoch 17/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.2619 - acc: 0.2742 - val_loss: 2.5031 - val_acc: 0.1263\n",
      "Epoch 18/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.1528 - acc: 0.2639 - val_loss: 2.0272 - val_acc: 0.3432\n",
      "Epoch 19/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.9099 - acc: 0.3378 - val_loss: 2.6721 - val_acc: 0.2905\n",
      "Epoch 20/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.8784 - acc: 0.3635 - val_loss: 5.7256 - val_acc: 0.2000\n",
      "Epoch 21/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.3327 - acc: 0.3081 - val_loss: 2.2249 - val_acc: 0.4253\n",
      "Epoch 22/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.2443 - acc: 0.3228 - val_loss: 3.2081 - val_acc: 0.3832\n",
      "Epoch 23/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.2445 - acc: 0.2938 - val_loss: 2.7196 - val_acc: 0.3347\n",
      "Epoch 24/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.4186 - acc: 0.2356 - val_loss: 2.6597 - val_acc: 0.0989\n",
      "Epoch 25/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.4337 - acc: 0.2063 - val_loss: 2.7202 - val_acc: 0.2695\n",
      "Epoch 26/50\n",
      "4275/4275 [==============================] - 278s - loss: 2.1869 - acc: 0.2770 - val_loss: 1.9771 - val_acc: 0.3495\n",
      "Epoch 27/50\n",
      "4275/4275 [==============================] - 279s - loss: 2.0226 - acc: 0.3359 - val_loss: 1.8629 - val_acc: 0.3642\n",
      "Epoch 28/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.9361 - acc: 0.3556 - val_loss: 2.0882 - val_acc: 0.4232\n",
      "Epoch 29/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.8324 - acc: 0.3806 - val_loss: 1.8417 - val_acc: 0.3979\n",
      "Epoch 30/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.7580 - acc: 0.3888 - val_loss: 1.9439 - val_acc: 0.4526\n",
      "Epoch 31/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.7307 - acc: 0.4068 - val_loss: 1.7637 - val_acc: 0.4716\n",
      "Epoch 32/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.7182 - acc: 0.4028 - val_loss: 2.6102 - val_acc: 0.2611\n",
      "Epoch 33/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.7583 - acc: 0.3937 - val_loss: 1.6179 - val_acc: 0.4653\n",
      "Epoch 34/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.6788 - acc: 0.4182 - val_loss: 1.6213 - val_acc: 0.4695\n",
      "Epoch 35/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.6350 - acc: 0.4248 - val_loss: 1.4702 - val_acc: 0.5179\n",
      "Epoch 36/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.6463 - acc: 0.4232 - val_loss: 1.5180 - val_acc: 0.4821\n",
      "Epoch 37/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.5966 - acc: 0.4433 - val_loss: 1.5704 - val_acc: 0.5116\n",
      "Epoch 38/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.5365 - acc: 0.4592 - val_loss: 1.4371 - val_acc: 0.4947\n",
      "Epoch 39/50\n",
      "4275/4275 [==============================] - 280s - loss: 1.5623 - acc: 0.4547 - val_loss: 1.4415 - val_acc: 0.5137\n",
      "Epoch 40/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.4852 - acc: 0.4781 - val_loss: 1.6555 - val_acc: 0.5032\n",
      "Epoch 41/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.5548 - acc: 0.4470 - val_loss: 1.7118 - val_acc: 0.4758\n",
      "Epoch 42/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.4884 - acc: 0.4833 - val_loss: 3.2173 - val_acc: 0.2653\n",
      "Epoch 43/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.4989 - acc: 0.4643 - val_loss: 3.1150 - val_acc: 0.3958\n",
      "Epoch 44/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.4514 - acc: 0.4812 - val_loss: 1.4926 - val_acc: 0.5916\n",
      "Epoch 45/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.4701 - acc: 0.4882 - val_loss: 1.4398 - val_acc: 0.5032\n",
      "Epoch 46/50\n",
      "4275/4275 [==============================] - 279s - loss: 1.4332 - acc: 0.4982 - val_loss: 1.7067 - val_acc: 0.5305\n",
      "Epoch 47/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.3919 - acc: 0.5137 - val_loss: 1.1341 - val_acc: 0.5979\n",
      "Epoch 48/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.3346 - acc: 0.5357 - val_loss: 1.2467 - val_acc: 0.5789\n",
      "Epoch 49/50\n",
      "4275/4275 [==============================] - 278s - loss: 1.2666 - acc: 0.5481 - val_loss: 1.3662 - val_acc: 0.5747\n",
      "Epoch 50/50\n",
      "4275/4275 [==============================] - 277s - loss: 1.3184 - acc: 0.5450 - val_loss: 1.0637 - val_acc: 0.6884\n",
      "fitting 50 took 13957 seconds\n"
     ]
    }
   ],
   "source": [
    "fitting_start_time = time.time()\n",
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=50, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model.save_weights('weights-100-epochs.h5')\n",
    "print \"fitting 50 took {} seconds\".format(int(time.time() - fitting_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4275/4275 [==============================] - 277s - loss: 1.2509 - acc: 0.5705 - val_loss: 1.4501 - val_acc: 0.6084\n",
      "Epoch 2/10\n",
      "4275/4275 [==============================] - 279s - loss: 1.2487 - acc: 0.5761 - val_loss: 1.7338 - val_acc: 0.4568\n",
      "Epoch 3/10\n",
      "4275/4275 [==============================] - 277s - loss: 1.2075 - acc: 0.5841 - val_loss: 1.1072 - val_acc: 0.6842\n",
      "Epoch 4/10\n",
      "4275/4275 [==============================] - 277s - loss: 1.1531 - acc: 0.5913 - val_loss: 1.1819 - val_acc: 0.6863\n",
      "Epoch 5/10\n",
      "4275/4275 [==============================] - 277s - loss: 1.1685 - acc: 0.6012 - val_loss: 1.0892 - val_acc: 0.6968\n",
      "Epoch 6/10\n",
      "4275/4275 [==============================] - 277s - loss: 1.1062 - acc: 0.6201 - val_loss: 1.0812 - val_acc: 0.7032\n",
      "Epoch 7/10\n",
      "4275/4275 [==============================] - 277s - loss: 1.1024 - acc: 0.6122 - val_loss: 0.9141 - val_acc: 0.7326\n",
      "Epoch 8/10\n",
      "4275/4275 [==============================] - 276s - loss: 1.1824 - acc: 0.6047 - val_loss: 1.9564 - val_acc: 0.5874\n",
      "Epoch 9/10\n",
      "4275/4275 [==============================] - 276s - loss: 1.1094 - acc: 0.6159 - val_loss: 1.0704 - val_acc: 0.7305\n",
      "Epoch 10/10\n",
      "4275/4275 [==============================] - 277s - loss: 1.0766 - acc: 0.6299 - val_loss: 1.1796 - val_acc: 0.6905\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('weights-100-epochs.h5')\n",
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model.save_weights('weights-110-epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4275/4275 [==============================] - 275s - loss: 1.0303 - acc: 0.6442 - val_loss: 1.0373 - val_acc: 0.6947\n",
      "Epoch 2/10\n",
      "4275/4275 [==============================] - 276s - loss: 1.0539 - acc: 0.6370 - val_loss: 0.9747 - val_acc: 0.6674\n",
      "Epoch 3/10\n",
      "4275/4275 [==============================] - 278s - loss: 1.0247 - acc: 0.6494 - val_loss: 0.8441 - val_acc: 0.7032\n",
      "Epoch 4/10\n",
      "4275/4275 [==============================] - 277s - loss: 0.9343 - acc: 0.6849 - val_loss: 0.8653 - val_acc: 0.7284\n",
      "Epoch 5/10\n",
      "4275/4275 [==============================] - 277s - loss: 0.9919 - acc: 0.6625 - val_loss: 1.0644 - val_acc: 0.7326\n",
      "Epoch 6/10\n",
      "4275/4275 [==============================] - 277s - loss: 0.9664 - acc: 0.6685 - val_loss: 1.0918 - val_acc: 0.7642\n",
      "Epoch 7/10\n",
      "4275/4275 [==============================] - 276s - loss: 0.9347 - acc: 0.6765 - val_loss: 8.1395 - val_acc: 0.2442\n",
      "Epoch 8/10\n",
      "4275/4275 [==============================] - 277s - loss: 1.0525 - acc: 0.6421 - val_loss: 1.3795 - val_acc: 0.7074\n",
      "Epoch 9/10\n",
      "4275/4275 [==============================] - 276s - loss: 1.0849 - acc: 0.6264 - val_loss: 0.8575 - val_acc: 0.6926\n",
      "Epoch 10/10\n",
      "4275/4275 [==============================] - 276s - loss: 0.9520 - acc: 0.6646 - val_loss: 0.8503 - val_acc: 0.7642\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model.save_weights('weights-120-epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4275/4275 [==============================] - 275s - loss: 1.0118 - acc: 0.6664 - val_loss: 1.0108 - val_acc: 0.7137\n",
      "Epoch 2/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.9127 - acc: 0.6837 - val_loss: 1.0477 - val_acc: 0.7474\n",
      "Epoch 3/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.8954 - acc: 0.6835 - val_loss: 0.9005 - val_acc: 0.7621\n",
      "Epoch 4/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.9105 - acc: 0.6896 - val_loss: 0.7694 - val_acc: 0.7705\n",
      "Epoch 5/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.8530 - acc: 0.7092 - val_loss: 1.2092 - val_acc: 0.7347\n",
      "Epoch 6/100\n",
      "4275/4275 [==============================] - 277s - loss: 0.8372 - acc: 0.7113 - val_loss: 1.0042 - val_acc: 0.7432\n",
      "Epoch 7/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.7944 - acc: 0.7308 - val_loss: 1.0605 - val_acc: 0.7137\n",
      "Epoch 8/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.8020 - acc: 0.7310 - val_loss: 0.7077 - val_acc: 0.7895\n",
      "Epoch 9/100\n",
      "4275/4275 [==============================] - 277s - loss: 0.7492 - acc: 0.7385 - val_loss: 0.7001 - val_acc: 0.7811\n",
      "Epoch 10/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.8668 - acc: 0.7092 - val_loss: 1.0234 - val_acc: 0.7242\n",
      "Epoch 11/100\n",
      "4275/4275 [==============================] - 279s - loss: 0.8173 - acc: 0.7263 - val_loss: 0.7429 - val_acc: 0.7979\n",
      "Epoch 12/100\n",
      "4275/4275 [==============================] - 277s - loss: 0.7511 - acc: 0.7364 - val_loss: 0.8724 - val_acc: 0.7432\n",
      "Epoch 13/100\n",
      "4275/4275 [==============================] - 277s - loss: 0.7788 - acc: 0.7368 - val_loss: 1.1188 - val_acc: 0.7137\n",
      "Epoch 14/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.7543 - acc: 0.7343 - val_loss: 0.9604 - val_acc: 0.7642\n",
      "Epoch 15/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.6997 - acc: 0.7577 - val_loss: 0.5887 - val_acc: 0.8547\n",
      "Epoch 16/100\n",
      "4275/4275 [==============================] - 277s - loss: 0.7427 - acc: 0.7460 - val_loss: 0.5906 - val_acc: 0.8042\n",
      "Epoch 17/100\n",
      "4275/4275 [==============================] - 277s - loss: 0.6772 - acc: 0.7656 - val_loss: 0.6623 - val_acc: 0.8147\n",
      "Epoch 18/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.6808 - acc: 0.7656 - val_loss: 0.4838 - val_acc: 0.8295\n",
      "Epoch 19/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.6607 - acc: 0.7698 - val_loss: 0.6787 - val_acc: 0.8211\n",
      "Epoch 20/100\n",
      "4275/4275 [==============================] - 277s - loss: 0.7363 - acc: 0.7464 - val_loss: 0.5565 - val_acc: 0.8211\n",
      "Epoch 21/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.7078 - acc: 0.7565 - val_loss: 0.6262 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "4275/4275 [==============================] - 277s - loss: 0.7144 - acc: 0.7558 - val_loss: 0.5798 - val_acc: 0.8126\n",
      "Epoch 23/100\n",
      "4275/4275 [==============================] - 277s - loss: 0.7299 - acc: 0.7612 - val_loss: 0.5556 - val_acc: 0.8274\n",
      "Epoch 24/100\n",
      "4275/4275 [==============================] - 277s - loss: 0.6649 - acc: 0.7804 - val_loss: 0.7381 - val_acc: 0.7558\n",
      "Epoch 25/100\n",
      "4275/4275 [==============================] - 278s - loss: 0.7690 - acc: 0.7478 - val_loss: 0.8062 - val_acc: 0.8253\n",
      "Epoch 26/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.6338 - acc: 0.7818 - val_loss: 0.7188 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.6237 - acc: 0.7825 - val_loss: 0.5006 - val_acc: 0.8547\n",
      "Epoch 28/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5909 - acc: 0.7897 - val_loss: 0.5589 - val_acc: 0.8526\n",
      "Epoch 29/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5959 - acc: 0.7977 - val_loss: 0.5918 - val_acc: 0.8526\n",
      "Epoch 30/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5978 - acc: 0.7942 - val_loss: 0.5620 - val_acc: 0.8632\n",
      "Epoch 31/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5618 - acc: 0.8096 - val_loss: 0.5440 - val_acc: 0.8547\n",
      "Epoch 32/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5639 - acc: 0.8028 - val_loss: 0.8598 - val_acc: 0.7937\n",
      "Epoch 33/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5605 - acc: 0.8096 - val_loss: 0.5135 - val_acc: 0.8421\n",
      "Epoch 34/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.7609 - acc: 0.7441 - val_loss: 0.7324 - val_acc: 0.7368\n",
      "Epoch 35/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.7296 - acc: 0.7506 - val_loss: 0.4813 - val_acc: 0.8505\n",
      "Epoch 36/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.6012 - acc: 0.7958 - val_loss: 0.5006 - val_acc: 0.8632\n",
      "Epoch 37/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5703 - acc: 0.8089 - val_loss: 0.9853 - val_acc: 0.8126\n",
      "Epoch 38/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5630 - acc: 0.8023 - val_loss: 0.9070 - val_acc: 0.8463\n",
      "Epoch 39/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5544 - acc: 0.8082 - val_loss: 0.4611 - val_acc: 0.8526\n",
      "Epoch 40/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5526 - acc: 0.8101 - val_loss: 0.4766 - val_acc: 0.8653\n",
      "Epoch 41/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5124 - acc: 0.8161 - val_loss: 0.9949 - val_acc: 0.8295\n",
      "Epoch 42/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.7027 - acc: 0.7637 - val_loss: 1.0817 - val_acc: 0.7705\n",
      "Epoch 43/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5179 - acc: 0.8192 - val_loss: 0.4934 - val_acc: 0.8505\n",
      "Epoch 44/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4987 - acc: 0.8246 - val_loss: 0.6758 - val_acc: 0.8611\n",
      "Epoch 45/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4857 - acc: 0.8353 - val_loss: 0.7882 - val_acc: 0.7747\n",
      "Epoch 46/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5022 - acc: 0.8299 - val_loss: 0.4309 - val_acc: 0.8589\n",
      "Epoch 47/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5525 - acc: 0.8164 - val_loss: 2.2059 - val_acc: 0.6632\n",
      "Epoch 48/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5708 - acc: 0.8105 - val_loss: 0.4370 - val_acc: 0.8800\n",
      "Epoch 49/100\n",
      "4275/4275 [==============================] - 274s - loss: 0.6646 - acc: 0.7804 - val_loss: 0.5406 - val_acc: 0.8421\n",
      "Epoch 50/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5594 - acc: 0.8122 - val_loss: 1.1133 - val_acc: 0.7600\n",
      "Epoch 51/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.7019 - acc: 0.7602 - val_loss: 0.5245 - val_acc: 0.8337\n",
      "Epoch 52/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5234 - acc: 0.8126 - val_loss: 0.4558 - val_acc: 0.8884\n",
      "Epoch 53/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5091 - acc: 0.8196 - val_loss: 0.4582 - val_acc: 0.8653\n",
      "Epoch 54/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4657 - acc: 0.8320 - val_loss: 0.6687 - val_acc: 0.8568\n",
      "Epoch 55/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4700 - acc: 0.8367 - val_loss: 0.6171 - val_acc: 0.8547\n",
      "Epoch 56/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4510 - acc: 0.8416 - val_loss: 0.4346 - val_acc: 0.8947\n",
      "Epoch 57/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4562 - acc: 0.8435 - val_loss: 0.7248 - val_acc: 0.8253\n",
      "Epoch 58/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5250 - acc: 0.8264 - val_loss: 1.6742 - val_acc: 0.6274\n",
      "Epoch 59/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.7335 - acc: 0.7490 - val_loss: 0.5678 - val_acc: 0.8295\n",
      "Epoch 60/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5864 - acc: 0.7986 - val_loss: 0.5036 - val_acc: 0.8463\n",
      "Epoch 61/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5213 - acc: 0.8150 - val_loss: 0.5714 - val_acc: 0.8800\n",
      "Epoch 62/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5125 - acc: 0.8218 - val_loss: 1.2631 - val_acc: 0.7095\n",
      "Epoch 63/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5418 - acc: 0.8122 - val_loss: 0.5757 - val_acc: 0.8379\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4275/4275 [==============================] - 276s - loss: 0.4801 - acc: 0.8346 - val_loss: 0.4604 - val_acc: 0.8968\n",
      "Epoch 65/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4647 - acc: 0.8337 - val_loss: 0.3989 - val_acc: 0.8863\n",
      "Epoch 66/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4233 - acc: 0.8505 - val_loss: 0.4860 - val_acc: 0.8737\n",
      "Epoch 67/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4464 - acc: 0.8414 - val_loss: 0.5746 - val_acc: 0.8547\n",
      "Epoch 68/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4606 - acc: 0.8384 - val_loss: 0.7716 - val_acc: 0.8632\n",
      "Epoch 69/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4414 - acc: 0.8470 - val_loss: 0.6584 - val_acc: 0.8442\n",
      "Epoch 70/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5339 - acc: 0.8133 - val_loss: 0.6580 - val_acc: 0.8758\n",
      "Epoch 71/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4248 - acc: 0.8508 - val_loss: 0.6180 - val_acc: 0.8400\n",
      "Epoch 72/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5694 - acc: 0.8105 - val_loss: 0.5504 - val_acc: 0.8316\n",
      "Epoch 73/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5271 - acc: 0.8204 - val_loss: 0.5580 - val_acc: 0.8737\n",
      "Epoch 74/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5257 - acc: 0.8124 - val_loss: 0.7376 - val_acc: 0.8484\n",
      "Epoch 75/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5239 - acc: 0.8164 - val_loss: 0.5610 - val_acc: 0.8779\n",
      "Epoch 76/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4517 - acc: 0.8428 - val_loss: 0.4635 - val_acc: 0.8821\n",
      "Epoch 77/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4166 - acc: 0.8547 - val_loss: 0.5487 - val_acc: 0.8800\n",
      "Epoch 78/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4152 - acc: 0.8618 - val_loss: 0.6298 - val_acc: 0.8674\n",
      "Epoch 79/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5434 - acc: 0.8180 - val_loss: 1.5376 - val_acc: 0.7495\n",
      "Epoch 80/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5463 - acc: 0.8075 - val_loss: 0.5793 - val_acc: 0.8526\n",
      "Epoch 81/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4865 - acc: 0.8330 - val_loss: 0.5858 - val_acc: 0.8358\n",
      "Epoch 82/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4466 - acc: 0.8416 - val_loss: 0.6662 - val_acc: 0.8653\n",
      "Epoch 83/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4209 - acc: 0.8473 - val_loss: 0.6674 - val_acc: 0.8905\n",
      "Epoch 84/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4160 - acc: 0.8531 - val_loss: 0.5600 - val_acc: 0.8863\n",
      "Epoch 85/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4062 - acc: 0.8501 - val_loss: 0.5846 - val_acc: 0.8716\n",
      "Epoch 86/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4387 - acc: 0.8458 - val_loss: 0.6710 - val_acc: 0.8779\n",
      "Epoch 87/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4238 - acc: 0.8468 - val_loss: 1.0282 - val_acc: 0.8253\n",
      "Epoch 88/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.5608 - acc: 0.8103 - val_loss: 0.6642 - val_acc: 0.8611\n",
      "Epoch 89/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4651 - acc: 0.8409 - val_loss: 0.5567 - val_acc: 0.8842\n",
      "Epoch 90/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4054 - acc: 0.8508 - val_loss: 0.3992 - val_acc: 0.8905\n",
      "Epoch 91/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5438 - acc: 0.8159 - val_loss: 1.0096 - val_acc: 0.7874\n",
      "Epoch 92/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.5151 - acc: 0.8206 - val_loss: 0.6474 - val_acc: 0.8758\n",
      "Epoch 93/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4653 - acc: 0.8381 - val_loss: 0.4666 - val_acc: 0.8632\n",
      "Epoch 94/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4432 - acc: 0.8484 - val_loss: 1.1154 - val_acc: 0.8189\n",
      "Epoch 95/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4189 - acc: 0.8512 - val_loss: 0.6230 - val_acc: 0.8758\n",
      "Epoch 96/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4824 - acc: 0.8295 - val_loss: 0.4996 - val_acc: 0.8842\n",
      "Epoch 97/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4271 - acc: 0.8515 - val_loss: 0.4356 - val_acc: 0.8926\n",
      "Epoch 98/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.4821 - acc: 0.8299 - val_loss: 0.4693 - val_acc: 0.8674\n",
      "Epoch 99/100\n",
      "4275/4275 [==============================] - 276s - loss: 0.4239 - acc: 0.8510 - val_loss: 0.4995 - val_acc: 0.8653\n",
      "Epoch 100/100\n",
      "4275/4275 [==============================] - 275s - loss: 0.3975 - acc: 0.8536 - val_loss: 0.5435 - val_acc: 0.8716\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=100, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model.save_weights('weights-220-epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 475 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = get_batches(path + '/valid', batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(predictions, axis = 1)\n",
    "actual_classes = val_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.8800%\n",
      "Recall score: 0.8800%\n",
      "F1: 0.8800%\n",
      "F1 calculated: 0.8800%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, log_loss, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(actual_classes, predicted_classes, average='micro');\n",
    "recall = recall_score(actual_classes, predicted_classes, average='micro')\n",
    "f1 = (2 * precision * recall) / (precision + recall)\n",
    "f1_calculated = f1_score(actual_classes, predicted_classes, average='micro')\n",
    "\n",
    "print 'Precision score: {:.4f}%'.format(precision)\n",
    "print 'Recall score: {:.4f}%'.format(recall)\n",
    "print 'F1: {:.4f}%'.format(f1)\n",
    "print 'F1 calculated: {:.4f}%'.format(f1_calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418 correct predictions found\n"
     ]
    }
   ],
   "source": [
    "idxs = np.where(actual_classes == predicted_classes)[0]\n",
    "print '{} correct predictions found'.format(len(idxs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run prediction and prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 794 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(path + '/test', batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "results_file = path + '/results/submission.csv'\n",
    "file = open(results_file, \"wb\")\n",
    "writer = csv.writer(file, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "header = ['file','species']\n",
    "writer.writerow(header)\n",
    "\n",
    "predicted_classes = np.argmax(predictions, axis = 1)\n",
    "\n",
    "\n",
    "for filename, prediction in zip(test_batches.filenames, predicted_classes):\n",
    "    writer.writerow([filename[len('unknown/'):]] + [sorted(categories)[prediction]])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chekalin/Dev/fast-ai-homework/seedling-classification\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='data/results/submission.csv' target='_blank'>data/results/submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/chekalin/Dev/fast-ai-homework/seedling-classification/data/results/submission.csv"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "%cd $HOME\n",
    "relative_path_to_results = results_file.replace(HOME, '')[1:]\n",
    "FileLink(relative_path_to_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
